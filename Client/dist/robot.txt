# Fichier robots.txt standardisé pour une application web
# Date de dernière modification : [11, 2025]

# =========================================================
# DIRECTIVES GÉNÉRALES (Pour tous les robots)
# =========================================================
User-agent: *

# Pages et zones qui ne doivent JAMAIS être explorées
#Disallow: /admin/
#Disallow: /login
#Disallow: /register
Disallow: /Pages/Private 

# Bloquer les URLs avec des paramètres (pour éviter le contenu dupliqué, 
# souvent utilisé par les filtres de recherche ou de tri)
Disallow: /*?
 
# Temps d'attente (Pour les vieux robots qui respectent encore cette directive)
Crawl-delay: 10

# =========================================================
# SITEMAPS (Indispensable pour le SEO)
# =========================================================
# Indique le chemin de votre sitemap(s). Remplacez 'votresite.com' par votre domaine.
Sitemap: https://www.votresite.com/sitemap.xml